{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            ############### IMPORTATION DES PACKAGES #################\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ################# IMPORTATION DES DATASETS ET CONCATENATION #####################\n",
    "\n",
    "# Chargement des fichiers PTB\n",
    "ptb_abnormal = pd.read_csv('ptbdb_abnormal.csv', header=None)\n",
    "ptb_normal = pd.read_csv('ptbdb_normal.csv', header=None)\n",
    "ptb = pd.concat([ptb_normal, ptb_abnormal], ignore_index=True, sort=False)\n",
    "ptb.rename(columns={187 :'class'}, inplace=True)\n",
    "    \n",
    "# Chargement des fichiers MITBIH\n",
    "mit_train = pd.read_csv('mitbih_train.csv', header=None)\n",
    "mit_test = pd.read_csv('mitbih_test.csv', header=None)\n",
    "mit = pd.concat([mit_train, mit_test], ignore_index=True, sort=False)\n",
    "mit.rename(columns={187 :'class'}, inplace=True)\n",
    "mit['class'].replace({2:1, 3:1, 4:1}, inplace=True)\n",
    "    \n",
    "# Concaténation des deux ensembles de données\n",
    "data = pd.concat([ptb, mit], ignore_index=True, sort=False)\n",
    "    \n",
    "# Variables cibles\n",
    "y = data['class'].copy()\n",
    "    \n",
    "# Features\n",
    "X = data.drop('class', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    ################# MODÈLE CATBOOST 1 ################\n",
    "                                    \n",
    "# Séparation en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1, shuffle=True)\n",
    "\n",
    "# Define the model with custom hyperparameters\n",
    "model = CatBoostClassifier(iterations=4000, learning_rate=0.08, depth=8, metric_period=100)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                              ####################### MODÈLE CATBOOST 2 #########################\n",
    "\n",
    "# Séparation en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1, shuffle=True)\n",
    "\n",
    "# Spécifier les hyperparamètres du modèle CatBoostClassifier\n",
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.08,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'border_count': 64, \n",
    "    'random_seed': 42,\n",
    "    'eval_metric': 'Accuracy', \n",
    "    'metric_period': 100\n",
    "}\n",
    "\n",
    "# Créer un modèle CatBoostClassifier avec les hyperparamètres spécifiés\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Obtenir les probabilités de prédiction pour la classe positive\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            ############## INTERPRETABILITÉ AVEC PACKAGE LIME #################\n",
    "\n",
    "# Utiliser la bibliothèque LIME pour expliquer les prédictions du modèle pour une observation spécifique\n",
    "explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, \n",
    "                                 class_names=['0 : normal', '1 : abnormal'], \n",
    "                                 discretize_continuous=True)\n",
    "\n",
    "exp = explainer.explain_instance(X_test.iloc[0,:].values, model.predict_proba, num_features=5)\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        ############ COURBE D'APPRENTISSAGE POUR UN POOL DE TRAIN ET TEST ####################                      \n",
    "\n",
    "# Définir les données d'entraînement et de test\n",
    "train_data = Pool(X_train, y_train)\n",
    "test_data = Pool(X_test, y_test)\n",
    "\n",
    "# Tracer les courbes d'apprentissage\n",
    "plt.plot(model.get_evals_result()['learn']['Accuracy'], label='Train set')\n",
    "plt.plot(model.get_evals_result()['validation']['Accuracy'], label='Test set')\n",
    "plt.title('Learning Curve CatBoost')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.legend()\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    ################# COURBE DE CALIBRATION ###################\n",
    "\n",
    "# Calculer la courbe de calibration\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "\n",
    "# Tracer la courbe de calibration\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\", color='red')\n",
    "\n",
    "# Tracer la diagonale parfaite\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Calibration Curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                ############ INTERPRÉTABILITÉ : FEATURE IMPORTANCE ##################\n",
    "\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh', color='red')\n",
    "plt.title('Feature importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            ############# MODÈLE CATBOOST 3 ##############\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000, \n",
    "                           learning_rate=0.1520172767474338, \n",
    "                           depth=9, \n",
    "                           l2_leaf_reg=1.4205108576277599, \n",
    "                           bagging_temperature=1.123731327207984, \n",
    "                           random_strength=0.19335447144110063,\n",
    "                           eval_metric='Logloss',\n",
    "                           metric_period=100,\n",
    "                           verbose=100)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print('AUC on test set:', auc)\n",
    "\n",
    "# Prédire les labels pour l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Afficher le classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                ############# MATRICE DE CONFUSION ################\n",
    "\n",
    "# Calculer la matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Créer une heatmap pour visualiser la matrice de confusion\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Classe prédite\")\n",
    "plt.ylabel(\"Classe réelle\")\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamètres qui peuvent être utiles dans le cadre de la classification avec CatBoost :\n",
    "\n",
    "> learning_rate : la vitesse à laquelle le modèle ajuste les poids des features lors de l'apprentissage. Une valeur plus élevée peut entraîner une convergence plus rapide mais peut également entraîner un surajustement.\n",
    "\n",
    "> max_depth : la profondeur maximale de l'arbre de décision. Une valeur plus élevée peut entraîner un surajustement.\n",
    "\n",
    "> l2_leaf_reg : le coefficient de régularisation L2 pour les feuilles de l'arbre de décision. Une valeur plus élevée peut aider à prévenir le surajustement.\n",
    "\n",
    "> bagging_temperature : contrôle l'agressivité du bagging. Des valeurs plus élevées peuvent aider à prévenir le surajustement.\n",
    "\n",
    "> border_count : le nombre de subdivisions à utiliser pour les features catégorielles. Des valeurs plus élevées peuvent améliorer la performance, mais cela peut également augmenter le temps d'entraînement.\n",
    "\n",
    "> learning_curve : le taux d'apprentissage est un hyperparamètre important qui contrôle la vitesse à laquelle le modèle apprend à partir des données. Un taux d'apprentissage trop élevé peut entraîner une instabilité du modèle, tandis qu'un taux d'apprentissage trop faible peut entraîner une convergence lente. C'est donc un hyperparamètre important à optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                ############## MODÈLE CATBOOST 4 ##############\n",
    "\n",
    "# Diviser les données en ensemble de train et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3.5 ; 4 ; \n",
    "# Spécifier les poids des classes\n",
    "class_weights = {0: 1, 1: 3}\n",
    "\n",
    "# Spécifier les hyperparamètres du modèle CatBoostClassifier\n",
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.08,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 8,\n",
    "    'bagging_temperature': 4, \n",
    "    'border_count': 64,  \n",
    "    'random_seed': 42,\n",
    "    'eval_metric': 'Accuracy', \n",
    "    'metric_period': 100,\n",
    "    'class_weights': class_weights\n",
    "}\n",
    "\n",
    "# Créer un modèle CatBoostClassifier avec les hyperparamètres spécifiés\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            ################ COURBE D'APPRENTISSAGE POUR UN POOL DE TRAIN ET TEST ################ \n",
    "\n",
    "# Définir les données d'entraînement et de test\n",
    "train_data = Pool(X_train, y_train)\n",
    "test_data = Pool(X_test, y_test)\n",
    "\n",
    "# Tracer les courbes d'apprentissage\n",
    "plt.plot(model.get_evals_result()['learn']['Accuracy'], label='Train set')\n",
    "plt.plot(model.get_evals_result()['validation']['Accuracy'], label='Test set')\n",
    "plt.title('Learning Curve CatBoost')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code utilise Optuna pour effectuer une optimisation hyperparamétrique d'un modèle CatBoostClassifier. Il utilise la validation croisée pour estimer la précision du modèle, et recherche les valeurs optimales pour les hyperparamètres suivants :\n",
    "\n",
    "- objective: la fonction d'objectif utilisée pour l'entraînement du modèle (log-loss ou cross-entropy)\n",
    "- colsample_bylevel: la fraction de colonnes à utiliser à chaque niveau de l'arbre\n",
    "- depth: la profondeur maximale de l'arbre\n",
    "- boosting_type: le type de boosting (ordered ou plain)\n",
    "- bootstrap_type: le type de bootstrap (Bayesian, Bernoulli, ou MVS)\n",
    "- bagging_temperature: la température pour le bootstrap bayésien\n",
    "- subsample: la fraction d'observations à utiliser pour le bootstrap bernoulli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    ############# MODÈLE CATBOOST 5 #################\n",
    "\n",
    "# Diviser les données en ensemble de train et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Spécifier les poids des classes\n",
    "class_weights = {0: 1, 1: 3}\n",
    "\n",
    "# Spécifier les hyperparamètres du modèle CatBoostClassifier\n",
    "params = {\n",
    "    'iterations': 3000,\n",
    "    'objective': 'Logloss',\n",
    "    'learning_rate': 0.08,\n",
    "    'colsample_bylevel': 0.022546586750624834,\n",
    "    'depth': 12,\n",
    "    'l2_leaf_reg': 8,\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'bagging_temperature': 9.954611183129638,  \n",
    "    'eval_metric': 'Accuracy', \n",
    "    'metric_period': 100,\n",
    "    'class_weights': class_weights \n",
    "}\n",
    "\n",
    "# Créer un modèle CatBoostClassifier avec les hyperparamètres spécifiés\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Obtenir les probabilités de prédiction pour la classe positive\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            ############ COURBE DE CALIBRATION ###############\n",
    "                                            \n",
    "# Calculer la courbe de calibration\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "\n",
    "# Tracer la courbe de calibration\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\", color='red')\n",
    "\n",
    "# Tracer la diagonale parfaite\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Calibration Curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        ################ COURBE D'APPRENTISSAGE POUR UN POOL DE TRAIN ET TEST ################ \n",
    "\n",
    "# Définir les données d'entraînement et de test\n",
    "train_data = Pool(X_train, y_train)\n",
    "test_data = Pool(X_test, y_test)\n",
    "\n",
    "# Tracer les courbes d'apprentissage\n",
    "plt.plot(model.get_evals_result()['learn']['Accuracy'], label='Train set')\n",
    "plt.plot(model.get_evals_result()['validation']['Accuracy'], label='Test set')\n",
    "plt.title('Learning Curve CatBoost')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    ################ MATRICE DE CONFUSION #################\n",
    "\n",
    "# Calculer la matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Créer une heatmap pour visualiser la matrice de confusion\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Classe prédite\")\n",
    "plt.ylabel(\"Classe réelle\")\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
